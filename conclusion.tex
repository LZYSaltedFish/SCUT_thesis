\chapter{总结与展望}

\section*{一、全文总结}

针对现有垂直领域检索增强对话生成的缺点与不足，本文对两方面内容展开了研究：一是基于内外部知识对齐的检索增强对话生成；二是基于人类偏好对齐的检索增强对话生成。通过所提出的两个新方法，本文能够较好的解决现有大部分垂直领域检索增强对话生成算法存在的问题。本论文的主要工作总结如下：

\begin{itemize}[topsep = 0 pt, itemsep= 0 pt, parsep=0pt, partopsep=0pt, leftmargin=20pt, itemindent=0pt, labelsep=6pt, listparindent=24pt]
	\item 针对模型内外部知识不一致，影响模型有效利用外部知识的问题，本文提出了基于内外部知识对齐的检索增强对话生成方法。该方法利用一个语义切分模块提取知识文档的文档级信息和实体级信息，并将提取出来的知识分别用于外部知识库构建和内部知识注入，实现垂直领域对话模型内外部知识对齐，更好地帮助提高模型回复的事实性和可靠性。

	\item 针对人类用户意图与模型理解之间存在偏差，造成模型生成不符合用户预期回答的问题，本文提出了基于人类偏好对齐的检索增强对话生成方法。该方法通过采集人类对真实场景对话样本的偏好，利用大型语言模型的理解与分析能力进行问题优化，并训练单独的问题优化语言模型，实现了与模型无关的、可解释、效果稳定的人类偏好对齐，使得对话模型生成的回复更准确有效。
	
    \item 本文通过大量的实验证明了所提出的两个方法的有效性和优越性。对于基于内外部知识对齐的垂直领域对话生成方法，本文将该方法应用于金融领域、云计算领域和法律领域，进行垂直领域知识问答任务实验，并在金融领域真实股票市场价格趋势预测任务上，通过多个评价维度验证其优于所有比较的方法。实验结果表明：内外部知识对齐有助于提升垂直领域对话生成的质量。对于基于人类偏好的对话生成对齐方法，本文分别在三个不同的基准测试机上与目前主流的语言模型对齐方法进行实验比较。实验结果表明：对用户问题进行优化，能同时提升知识文档召回准确率和模型理解与用户意图的一致性。
\end{itemize}

\section*{二、未来展望}

本文围绕面向专有领域的检索增强对话生成对齐课题开展研究并取得了一定的成果。然而，作为深度学习和自然语言处理的前沿研究方向之一，检索增强对话生成对齐仍然面临诸多困难与挑战。未来的工作主要总结为如下几个方面：

\begin{itemize}[topsep = 0 pt, itemsep= 0 pt, parsep=0pt, partopsep=0pt, leftmargin=20pt, itemindent=0pt, labelsep=6pt, listparindent=24pt]
	\item 对于基于内外部知识对齐的检索增强对话生成方法，本文仅考虑了文本模态的外部知识，而其他模态，如图像、语音等模态数据可能包含更多有助于模型进行金融分析的信息，进一步提升对话模型性能。为了解决这一问题，未来工作将进行多模态文档增强的探索，并探究如何利用多模态大模型的图文理解与生成能力，从而实现利用多模态信息的知识提升方法性能。
    
    % \item 本文所提出的两种方法仅在金融分析这一领域中验证了其有效性，未来工作将在更多的专有领域和数据集上验证这两个方法，探究其广泛适用性。
    
    \item 本文所提出的两种方法都基于大型语言模型的检索增强生成技术，方法的有效性在一定程度上对知识文档的质量和所使用的语言模型的指令遵循能力存在依赖性。未来工作将针对低信噪比外部知识和小尺寸基座模型的检索增强对话生成方式进行改进，提出一种新的方法，降低对话生成对文档和基座模型的敏感度。
    
    \item 对于基于人类偏好对齐的检索增强对话生成方法，该方法显式地引入了人类标注者的主观偏好，因此最终生成的对话回复可能会受到标注者的价值观影响。未来工作将探究如何减弱标注者个人偏好对方法性能的影响，实现更广泛的人类偏好对齐。
\end{itemize}